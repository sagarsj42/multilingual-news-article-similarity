{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /scratch/dhaval.taunk/torch-cache\n",
    "!mkdir -p /scratch/dhaval.taunk/transformers\n",
    "import os\n",
    "os.chdir('/scratch/dhaval.taunk')\n",
    "os.environ['TORCH_HOME'] = '/scratch/dhaval.taunk/torch-cache'\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/scratch/dhaval.taunk/transformers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torchmetrics\n",
    "\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaModel\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !echo 'yes' | scp dhaval.taunk@ada:/share1/dhaval.taunk/semeval8-train-sss.csv .\n",
    "# !echo 'yes' | scp dhaval.taunk@ada:/share1/dhaval.taunk/semeval8-dev.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda'), 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "N_GPUS = torch.cuda.device_count()\n",
    "\n",
    "DEVICE, N_GPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Feb  1 23:39:32 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.95.01    Driver Version: 440.95.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 36%   30C    P0    45W / 250W |     11MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = 'mlns-distilbert-regressor'\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "DEV_BATCH_SIZE = 8\n",
    "ACCUMULATE_GRAD = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityRegressor(nn.Module):\n",
    "    def __init__(self, encoder, embed_size=768, hidden_size=256):\n",
    "        super(SimilarityRegressor, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.linear1 = nn.Linear(self.embed_size, self.hidden_size)\n",
    "        self.activation1 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.linear2 = nn.Linear(2*self.hidden_size, self.hidden_size//2)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.activation2 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.linear3 = nn.Linear(self.hidden_size//2, 1)\n",
    "        self.activation3 = nn.Sigmoid()\n",
    "\n",
    "    def common_compute(self, x):\n",
    "        # print(self.encoder(**x)[0].shape)\n",
    "        x = self.encoder(**x)[0][:, 0]\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.common_compute(x1)\n",
    "        x2 = self.common_compute(x2)\n",
    "        x = torch.cat([torch.abs(x1 - x2), (x1 + x2)], dim=-1)\n",
    "        x = self.linear2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.linear3(x)\n",
    "        x = 3*self.activation3(x) + 1\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitSimilarityRegressor(pl.LightningModule):\n",
    "    def __init__(self, encoder, embed_size=768, hidden_size=256):\n",
    "        super(LitSimilarityRegressor, self).__init__()\n",
    "        self.model = SimilarityRegressor(encoder, embed_size=embed_size, hidden_size=hidden_size)\n",
    "\n",
    "        self.train_loss = torchmetrics.MeanMetric(compute_on_step=True)\n",
    "        self.dev_loss = torchmetrics.MeanMetric(compute_on_step=False)\n",
    "\n",
    "        self.train_mape = torchmetrics.MeanAbsolutePercentageError(compute_on_step=True)\n",
    "        self.dev_mape = torchmetrics.MeanAbsolutePercentageError(compute_on_step=False)\n",
    "\n",
    "        self.train_pcc = torchmetrics.PearsonCorrCoef(compute_on_step=True)\n",
    "        self.dev_pcc = torchmetrics.PearsonCorrCoef(compute_on_step=False)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        return self.model(x1, x2)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.parameters(), lr=1e-5, betas=(0.9, 0.99), eps=1e-8, weight_decay=0.01)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x1, x2, scores = batch\n",
    "        output = self(x1, x2)\n",
    "        loss = F.mse_loss(input=output, target=scores)\n",
    "\n",
    "        return {'loss': loss, 'preds': output, 'target': scores}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x1, x2, scores = batch\n",
    "        output = self(x1, x2)\n",
    "        loss = F.mse_loss(input=output, target=scores)\n",
    "\n",
    "        return {'loss': loss, 'preds': output, 'target': scores}\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x1, x2, _ = batch\n",
    "        output = self(x1, x2)\n",
    "\n",
    "        return {'preds': output}\n",
    "\n",
    "    def training_step_end(self, outs):\n",
    "        loss = outs['loss']\n",
    "        preds = outs['preds']\n",
    "        target = outs['target']\n",
    "\n",
    "        self.log('train/step/loss', self.train_loss(loss))\n",
    "        self.log('train/step/mape', self.train_mape(preds, target))\n",
    "        self.log('train/step/pcc', self.train_pcc(preds, target))\n",
    "\n",
    "    def validation_step_end(self, outs):\n",
    "        loss = outs['loss']\n",
    "        preds = outs['preds']\n",
    "        target = outs['target']\n",
    "\n",
    "        self.dev_loss(loss)\n",
    "        self.dev_mape(preds, target)\n",
    "        self.dev_pcc(preds, target)\n",
    "\n",
    "    def training_epoch_end(self, outs):\n",
    "        self.log('train/epoch/loss', self.train_loss)\n",
    "        self.log('train/epoch/mape', self.train_mape)\n",
    "        self.log('train/epoch/pcc', self.train_pcc)\n",
    "\n",
    "    def validation_epoch_end(self, outs):\n",
    "        self.log('dev/loss', self.dev_loss)\n",
    "        self.log('dev/mape', self.dev_mape)\n",
    "        self.log('dev/pcc', self.dev_pcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilingualNewsSimDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super(MultilingualNewsSimDataset, self).__init__()\n",
    "        self.df = df\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.df.iloc[idx][['pair_id', 'meta_description_1', 'title_1', 'text_1', 'meta_description_2', 'title_2', 'text_2', 'score']].to_dict()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch, tokenizer):\n",
    "    texts_1, texts_2, scores = list(), list(), list()\n",
    "    for sample in batch:\n",
    "        text1 = str(sample['title_1']).lower().strip()+str(sample['meta_description_1']).lower().strip()#+str(sample['text_1']).lower().strip()\n",
    "        text2 = str(sample['title_2']).lower().strip()+str(sample['meta_description_2']).lower().strip()#+str(sample['text_2']).lower().strip()\n",
    "\n",
    "        score = torch.tensor([sample['score']])\n",
    "        texts_1.append(text1)\n",
    "        texts_2.append(text2)\n",
    "        scores.append(score)\n",
    "\n",
    "    texts_1 = tokenizer(texts_1, truncation=True, padding=True, return_tensors='pt')\n",
    "    texts_2 = tokenizer(texts_2, truncation=True, padding=True, return_tensors='pt')\n",
    "    scores = torch.cat(scores, dim=0).unsqueeze(1)\n",
    "\n",
    "    return texts_1, texts_2, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLNSDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_dataset, dev_dataset, test_dataset, train_batch_size, dev_batch_size, collate_fn, tokenizer):\n",
    "        super(MLNSDataModule, self).__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.dev_dataset = dev_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.dev_batch_size = dev_batch_size\n",
    "        self.collate_fn = collate_fn\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        collate_partial = partial(self.collate_fn, tokenizer=self.tokenizer)\n",
    "        return DataLoader(self.train_dataset, shuffle=True, batch_size=self.train_batch_size, collate_fn=collate_partial)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        collate_partial = partial(self.collate_fn, tokenizer=self.tokenizer)\n",
    "        return DataLoader(self.dev_dataset, shuffle=False, batch_size=self.dev_batch_size, collate_fn=collate_partial)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        collate_partial = partial(self.collate_fn, tokenizer=self.tokenizer)\n",
    "        return DataLoader(self.test_dataset, shuffle=False, batch_size=self.dev_batch_size, collate_fn=collate_partial)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return self.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "# encoder = XLMRobertaModel.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
    "\n",
    "encoder = AutoModel.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
    "\n",
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4467, 20), (497, 20), (4953, 20))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('~/semeval/semeval8-train-sss.csv', index_col=0)\n",
    "dev_df = pd.read_csv('~/semeval/semeval8-dev.csv', index_col=0)\n",
    "test_df = pd.read_csv('~/semeval/semeval-2022-task-8-eval-df.csv', index_col=0)\n",
    "\n",
    "train_df.shape, dev_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4467, 497, 4953)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = MultilingualNewsSimDataset(train_df)\n",
    "dev_dataset = MultilingualNewsSimDataset(dev_df)\n",
    "test_dataset = MultilingualNewsSimDataset(test_df)\n",
    "\n",
    "len(train_dataset), len(dev_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([[   101,  10163,  62039,  10206,  32468,  30952,  10168,  36489,  12276,\n",
       "           34478,  18010,  11627,  29239,  10350,  10908,  23122,  10525,    118,\n",
       "             171,    100,  10176,  26397,    254,    180,    100,  38425,  16934,\n",
       "             172,    100,  10151,  33066,  10121,  10152,  34478,  55208,  97150,\n",
       "           10141,  13337,  12576,  10109,  41522,  61476,    118,  81441,    119,\n",
       "           10231,  43873,  29759,  19224,  10148,  21427,  10426,  10345,  16272,\n",
       "           51014,  10112,    117,  48993,  43555,  40726,  10127,  62862,  13484,\n",
       "           11010,  10116,    119,    102],\n",
       "         [   101,    761,  48674,  19445,  59901,  73261,  75373,  10210,    782,\n",
       "           33352,    759,  40828, 101269,  10582,    787,  29426,  41003,  10535,\n",
       "           10289,    766,  11687,  56363,    786,  52274,  14695,  59901,  73261,\n",
       "           51731,  10658,  13470,    102,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])},\n",
       " {'input_ids': tensor([[   101,  10110,  46770,  10110,  32461,  39639,  10112,    117,  23491,\n",
       "           28830,    187,  60341,  10119,  35562,  73099,  88389,  17791,  10526,\n",
       "           73061,  11189,  10460,  10163,  62039,  10206,  13386,  30656,  10131,\n",
       "           10151,  33066,    117,  10355,  11378,  10326,  21984,  10333,  10109,\n",
       "           34862,  10104,  10222,    117,  11170,  13362,  17577,  10260,  10141,\n",
       "           20784,  10104,    180,    100,  40473,  10426,  10131,  10104,    180,\n",
       "             100,  35518,    119,    102,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "               0,      0,      0],\n",
       "         [   101,    782,  33352,    766,  48674,  11852,    788,  49506,  26897,\n",
       "           10742,    763,  41002,  84234,  10429,  10289,    766,  11687,  56363,\n",
       "           10210,  53797,    786,  52274,  14695,  68715,  10502,  48979,  59901,\n",
       "           35849,  28241,  18562,    791,  13154,  94558,  81562, 101264,  10210,\n",
       "             785,  62884,    782,  33352,    752,    761,  48674,  19445,  59901,\n",
       "           73261,  75373,  48486,  10289,    784,  24618,  31074,  39539,  14653,\n",
       "             759,  40828, 101269,  10582,    752,  16849,  50643,    766,  11687,\n",
       "           56363,  10210,  53797,    786,  52274,  14695,  59901,  73261,  51731,\n",
       "           10658,    752,  37792, 102823,  10502,  48979, 101107,  10210,    119,\n",
       "             119,    119,    102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])},\n",
       " tensor([[3.],\n",
       "         [2.]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collate_partial = partial(collate_fn, tokenizer=tokenizer)\n",
    "dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_partial)\n",
    "batch = next(iter(dataloader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1, x2, _ = batch\n",
    "# outputs = model(x1.to(DEVICE), x2.to(DEVICE))\n",
    "# outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MLNSDataModule at 0x153396139e80>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module = MLNSDataModule(train_dataset, dev_dataset, test_dataset, TRAIN_BATCH_SIZE, DEV_BATCH_SIZE, collate_fn=collate_fn, tokenizer=tokenizer)\n",
    "data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LitSimilarityRegressor(\n",
       "  (model): SimilarityRegressor(\n",
       "    (encoder): DistilBertModel(\n",
       "      (embeddings): Embeddings(\n",
       "        (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (transformer): Transformer(\n",
       "        (layer): ModuleList(\n",
       "          (0): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear1): Linear(in_features=768, out_features=512, bias=True)\n",
       "    (activation1): LeakyReLU(negative_slope=0.1)\n",
       "    (dropout1): Dropout(p=0.2, inplace=False)\n",
       "    (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (dropout2): Dropout(p=0.2, inplace=False)\n",
       "    (activation2): LeakyReLU(negative_slope=0.1)\n",
       "    (linear3): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (activation3): Sigmoid()\n",
       "  )\n",
       "  (train_loss): MeanMetric()\n",
       "  (dev_loss): MeanMetric()\n",
       "  (train_mape): MeanAbsolutePercentageError()\n",
       "  (dev_mape): MeanAbsolutePercentageError()\n",
       "  (train_pcc): PearsonCorrCoef()\n",
       "  (dev_pcc): PearsonCorrCoef()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LitSimilarityRegressor(encoder, embed_size=768, hidden_size=512)\n",
    "\n",
    "\n",
    "# model = LitSimilarityRegressor.load_from_checkpoint(encoder, )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytorch_lightning.loggers.wandb.WandbLogger at 0x1533e0159f40>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger = pl.loggers.WandbLogger(save_dir=EXP_NAME, project=EXP_NAME, log_model=False)\n",
    "logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelCheckpoint(save_last=True, save_top_k=-1, monitor=None) will duplicate the last checkpoint saved.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=os.path.join(EXP_NAME, 'lightning-checkpoints'),\n",
    "    filename='{epoch}-{step}',\n",
    "    # monitor='dev/pcc',\n",
    "    # mode='max',\n",
    "    save_top_k=-1,\n",
    "    verbose=True,\n",
    "    save_last=True,\n",
    "    save_weights_only=False,\n",
    "    every_n_epochs=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pytorch_lightning.trainer.trainer.Trainer at 0x1533e51816d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accumulate_grad_batches=ACCUMULATE_GRAD,\n",
    "    accelerator='gpu',\n",
    "    gpus=1,\n",
    "    # overfit_batches=10,\n",
    "    check_val_every_n_epoch=1, val_check_interval=0.25,\n",
    "    log_every_n_steps=2, enable_progress_bar=True,\n",
    "    gradient_clip_val=0.25, track_grad_norm=2,\n",
    "    enable_checkpointing=True,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    logger=logger,\n",
    "    enable_model_summary=True\n",
    ")\n",
    "    \n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /scratch/dhaval.taunk/mlns-distilbert-regressor/lightning-checkpoints/epoch=7-step=2238.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Restored all states from the checkpoint file at /scratch/dhaval.taunk/mlns-distilbert-regressor/lightning-checkpoints/epoch=7-step=2238.ckpt\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name       | Type                        | Params\n",
      "-----------------------------------------------------------\n",
      "0 | model      | SimilarityRegressor         | 135 M \n",
      "1 | train_loss | MeanMetric                  | 0     \n",
      "2 | dev_loss   | MeanMetric                  | 0     \n",
      "3 | train_mape | MeanAbsolutePercentageError | 0     \n",
      "4 | dev_mape   | MeanAbsolutePercentageError | 0     \n",
      "5 | train_pcc  | PearsonCorrCoef             | 0     \n",
      "6 | dev_pcc    | PearsonCorrCoef             | 0     \n",
      "-----------------------------------------------------------\n",
      "135 M     Trainable params\n",
      "0         Non-trainable params\n",
      "135 M     Total params\n",
      "541.562   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/dhaval.taunk/miniconda3/envs/semeval/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6734a2587254f96bb0fa775625c4517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/dhaval.taunk/miniconda3/envs/semeval/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/closure.py:35: LightningDeprecationWarning: One of the returned values {'target', 'preds'} has a `grad_fn`. We will detach it automatically but this behaviour will change in v1.6. Please detach it manually: `return {'loss': ..., 'something': something.detach()}`\n",
      "  rank_zero_deprecation(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhaval08\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/dhaval08/mlns-distilbert-regressor/runs/15h7ewom\" target=\"_blank\">brilliant-paper-9</a></strong> to <a href=\"https://wandb.ai/dhaval08/mlns-distilbert-regressor\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint...\n",
      "/home2/dhaval.taunk/miniconda3/envs/semeval/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 26589... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf0cd1eaf84430a96109f488cd7e716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=data_module, ckpt_path = '/scratch/dhaval.taunk/mlns-distilbert-regressor/lightning-checkpoints/epoch=7-step=2238.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = trainer.predict(model, datamodule=data_module, ckpt_path='/scratch/dhaval.taunk/mlns-distilbert-regressor/lightning-checkpoints/last.ckpt')\n",
    "len(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs = list()\n",
    "for batch_outputs in test_pred:\n",
    "    all_outputs.append(batch_outputs['preds'])\n",
    "all_outputs = torch.cat(all_outputs, dim=0)\n",
    "\n",
    "all_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(zip(test_df.pair_id, all_outputs.squeeze(1).tolist())), columns=['pair_id', 'Overall']).to_csv('test-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip results_8_epochs_distbert_not_linear2.zip test-results.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57ba542a7e01434f0efba8458620b8a5d586d5cdb58a6ff11a95f38e977018f2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
